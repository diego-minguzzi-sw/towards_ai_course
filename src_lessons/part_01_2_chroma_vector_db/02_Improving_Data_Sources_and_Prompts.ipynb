{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29dd8eb4-60b8-4d7b-a6cb-1428a5b33287",
   "metadata": {},
   "source": [
    "# Towards AI Online course: Improving Data Sources and Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d486ecaf-7fc6-4e78-88ec-40b7a0025f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, Settings, VectorStoreIndex\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "import chromadb\n",
    "import csv\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ab1ebd-9813-4fe0-98cc-db53e3a5792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factorize all constants here.\n",
    "EmbeddingModel='text-embedding-3-small'\n",
    "\n",
    "CollectionName= 'mini-llama-articles'\n",
    "VectorDbPath= f'./{CollectionName}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e12d2c8f-0578-46fb-b41d-4ab1c92be8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = OpenAIEmbedding( model=EmbeddingModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "004ca451-5bcc-484d-a8ed-07e2027c11db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chromaClient = chromadb.PersistentClient(path= VectorDbPath)\n",
    "collection = chromaClient.get_or_create_collection(name=CollectionName)\n",
    "isCollectionEmpty= (0 == collection.count())\n",
    "isCollectionEmpty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77259070-84a6-43d0-a92f-a0361c11f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStore = ChromaVectorStore(chroma_collection=collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa5d21e-eea3-41ae-9afe-ee62c4da717d",
   "metadata": {},
   "source": [
    "## Downloads and prepares the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61e73058-cc4a-45ed-b6b3-17b80bd2d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed 'another_dataset/mini-dataset.csv'\n",
      "removed directory 'another_dataset'\n",
      "mkdir: created directory 'another_dataset'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  169k  100  169k    0     0   642k      0 --:--:-- --:--:-- --:--:--  644k\n"
     ]
    }
   ],
   "source": [
    "!rm -rfv another_dataset\n",
    "!mkdir -pv another_dataset\n",
    "!curl -o ./another_dataset/mini-dataset.csv https://raw.githubusercontent.com/AlaFalaki/tutorial_notebooks/main/data/mini-llama-articles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3baa3b4-ace9-4db1-a724-93fe247a8168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "with open(\"./another_dataset/mini-dataset.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "  csvReader = csv.reader(file)\n",
    "\n",
    "  for index, row in enumerate(csvReader):\n",
    "    if index == 0: \n",
    "        continue; # Skip header row\n",
    "    rows.append(row)\n",
    "\n",
    "# The number of characters in the dataset.\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4798f728-d8c3-4614-b2c5-5e7a32c9f646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Beyond GPT-4: What's New?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26994fee-6976-4a10-afe5-87fd626b2ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents:14\n"
     ]
    }
   ],
   "source": [
    "documents = [Document(text=row[1], metadata={\"title\": row[0], \"url\": row[2], \"sourceName\": row[3]}) for row in rows]\n",
    "print(f'Number of documents:{len(documents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5baec11f-f8ab-4a43-986e-dbe38eb7c1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Beyond GPT-4: What's New?\",\n",
       " 'url': 'https://pub.towardsai.net/beyond-gpt-4-whats-new-cbd61a448eb9#dda8',\n",
       " 'sourceName': 'towards_ai'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspects the metadata related to a document.\n",
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a934f4-f713-49d3-a35c-1186616a75a5",
   "metadata": {},
   "source": [
    "## Processes the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e016901f-b7aa-4623-8deb-b5399a9e197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "textSplitter = TokenTextSplitter( separator=\" \", chunk_size=512, chunk_overlap=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b749868e-d31d-4c37-918c-e03790360822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c416a69f4e418cafeddcf8022bf79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5150728b11a6438a929672ec773669a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        textSplitter,\n",
    "        OpenAIEmbedding(model = 'text-embedding-3-small'),\n",
    "    ],\n",
    "    vector_store=vectorStore\n",
    ")\n",
    "nodes = pipeline.run(documents=documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5efa732-4a93-419d-8934-56568f239ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_vector_store(vectorStore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e78ae4-904a-471f-94df-994902bce0cc",
   "metadata": {},
   "source": [
    "## Queries the document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb9c6b8d-bc71-472b-901e-a6bd2e41e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Gemini(model=\"models/gemini-2.0-flash\", temperature=1, max_tokens=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a1d5c7c-ac12-49e3-973f-53025b7cb597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Llama 2 model is available in four sizes: 7 billion, 13 billion, 34 billion, and 70 billion parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queryEngine = index.as_query_engine(llm=llm, similarity_top_k=5)\n",
    "res = queryEngine.query(\"How many parameters LLaMA2 model has?\")\n",
    "\n",
    "print(res.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "585e5edc-05d7-4c43-a1bc-52520aa5040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID\t 79b6aeec-c502-4b4c-a474-a573f095e841\n",
      "Title\t Fine-Tuning a Llama-2 7B Model for Python Code Generation\n",
      "Score\t 0.3637786840450056\n",
      "URL\t https://pub.towardsai.net/fine-tuning-a-llama-2-7b-model-for-python-code-generation-865453afdf73#bf4e\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t a2ef178f-a57b-42af-9cfa-7eb9bd267889\n",
      "Title\t Meta's Llama 2: Revolutionizing Open Source Language Models for Commercial Use\n",
      "Score\t 0.3566809510280558\n",
      "URL\t https://pub.towardsai.net/metas-llama-2-revolutionizing-open-source-language-models-for-commercial-use-1492bec112b#148f\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t 300ff917-2a24-48a9-805c-15581108f942\n",
      "Title\t Fine-Tuning a Llama-2 7B Model for Python Code Generation\n",
      "Score\t 0.35481100704185614\n",
      "URL\t https://pub.towardsai.net/fine-tuning-a-llama-2-7b-model-for-python-code-generation-865453afdf73#bf4e\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t 37b66172-43e9-4243-bb95-151245e43d2d\n",
      "Title\t LLaMA-GPT4All: Simplified Local ChatGPT\n",
      "Score\t 0.35237537118194534\n",
      "URL\t https://pub.towardsai.net/llama-gpt4all-simplified-local-chatgpt-ab7d28d34923#485a\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t 52777f2e-1351-4c41-839b-8eb4a0e13808\n",
      "Title\t Exploring Large Language Models -Part 3\n",
      "Score\t 0.3522424039572514\n",
      "URL\t https://pub.towardsai.net/exploring-large-language-models-part-3-ab60ee236950#d193\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
     ]
    }
   ],
   "source": [
    "for src in res.source_nodes:\n",
    "    print(\"Node ID\\t\", src.node_id)\n",
    "    print(\"Title\\t\", src.metadata[\"title\"])\n",
    "    print(\"Score\\t\", src.score)\n",
    "    print(\"URL\\t\", src.metadata[\"url\"])\n",
    "    print(\"-_\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abebc3f-0094-4bc6-98a3-8d687177edf0",
   "metadata": {},
   "source": [
    "## Response modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b9cf851-cec4-4cda-a3ef-427c2d8eb89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryEngineRefine = index.as_query_engine(response_mode=\"refine\", llm=llm, similarity_top_k=3)\n",
    "res = queryEngineRefine.query(\"How many parameters LLaMA2 model has?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44bf3216-d123-4505-a01e-4cc64e1c85d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Llama 2 model is available in four sizes: 7 billion, 13 billion, 34 billion, and 70 billion parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e41bf079-a06f-486f-9db4-93a7e6c53048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID\t 79b6aeec-c502-4b4c-a474-a573f095e841\n",
      "Title\t Fine-Tuning a Llama-2 7B Model for Python Code Generation\n",
      "Score\t 0.3637786840450056\n",
      "URL\t https://pub.towardsai.net/fine-tuning-a-llama-2-7b-model-for-python-code-generation-865453afdf73#bf4e\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t a2ef178f-a57b-42af-9cfa-7eb9bd267889\n",
      "Title\t Meta's Llama 2: Revolutionizing Open Source Language Models for Commercial Use\n",
      "Score\t 0.3566809510280558\n",
      "URL\t https://pub.towardsai.net/metas-llama-2-revolutionizing-open-source-language-models-for-commercial-use-1492bec112b#148f\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t 300ff917-2a24-48a9-805c-15581108f942\n",
      "Title\t Fine-Tuning a Llama-2 7B Model for Python Code Generation\n",
      "Score\t 0.35481100704185614\n",
      "URL\t https://pub.towardsai.net/fine-tuning-a-llama-2-7b-model-for-python-code-generation-865453afdf73#bf4e\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
     ]
    }
   ],
   "source": [
    "for src in res.source_nodes:\n",
    "    print(\"Node ID\\t\", src.node_id)\n",
    "    print(\"Title\\t\", src.metadata[\"title\"])\n",
    "    print(\"Score\\t\", src.score)\n",
    "    print(\"URL\\t\", src.metadata[\"url\"])\n",
    "    print(\"-_\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f22e8c-f620-4a48-9a88-a999fb69a138",
   "metadata": {},
   "source": [
    "### The No Text - Response Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a43e475-45cf-41cd-823d-77b0376dd301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "queryEngineRefine = index.as_query_engine(response_mode=\"no_text\", llm=llm, similarity_top_k=3)\n",
    "res = queryEngineRefine.query(\"How many parameters LLaMA2 model has?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0538c13d-6322-4e9d-b4b8-c9b42f860b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID\t 79b6aeec-c502-4b4c-a474-a573f095e841\n",
      "Title\t Fine-Tuning a Llama-2 7B Model for Python Code Generation\n",
      "Score\t 0.3637786840450056\n",
      "URL\t https://pub.towardsai.net/fine-tuning-a-llama-2-7b-model-for-python-code-generation-865453afdf73#bf4e\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t a2ef178f-a57b-42af-9cfa-7eb9bd267889\n",
      "Title\t Meta's Llama 2: Revolutionizing Open Source Language Models for Commercial Use\n",
      "Score\t 0.3566809510280558\n",
      "URL\t https://pub.towardsai.net/metas-llama-2-revolutionizing-open-source-language-models-for-commercial-use-1492bec112b#148f\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n",
      "Node ID\t 300ff917-2a24-48a9-805c-15581108f942\n",
      "Title\t Fine-Tuning a Llama-2 7B Model for Python Code Generation\n",
      "Score\t 0.35481100704185614\n",
      "URL\t https://pub.towardsai.net/fine-tuning-a-llama-2-7b-model-for-python-code-generation-865453afdf73#bf4e\n",
      "-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_-_\n"
     ]
    }
   ],
   "source": [
    "for src in res.source_nodes:\n",
    "    print(\"Node ID\\t\", src.node_id)\n",
    "    print(\"Title\\t\", src.metadata[\"title\"])\n",
    "    print(\"Score\\t\", src.score)\n",
    "    print(\"URL\\t\", src.metadata[\"url\"])\n",
    "    print(\"-_\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
