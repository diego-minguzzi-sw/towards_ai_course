{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29814780-6d66-4023-8723-63a80602d6e0",
   "metadata": {},
   "source": [
    "# Structuring Your Data\n",
    "\n",
    "## Structured Data in LLM(s)\n",
    "Structured data in LLM: the LLM generates JSON or XML output data, according to a schema.<br>\n",
    "A first attempt is add the to prompt, the instructions on how to generate the output, e.g. the format and the schema.  \n",
    "Moreover, usually some examples of output are provided.  This approach seems effective, but it is unreliable.<br>\n",
    "There is no guarantee that the model adheres to the specificed format.<br>\n",
    "<p/>\n",
    "<b>Response format</b> Another technique is using the <code>response_format</code> argument.<br>\n",
    "Hint: with structed output, use a low temperature, e.g. ZERO.<br>\n",
    "\n",
    "## Structured Data with OpenAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a92f305-2ccb-4855-a7c4-8b0a138c2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, TypeAdapter\n",
    "from typing import List\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218b9b7c-c063-4acb-8cc5-c9723ab65179",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_KEY_NAME='OPENAI_API_KEY'\n",
    "assert OPEN_AI_KEY_NAME in os.environ\n",
    "\n",
    "TAI_DATASET_ROOT_ENV_VAR='TAI_DATASET_ROOT'\n",
    "assert TAI_DATASET_ROOT_ENV_VAR in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b34ce83e-833b-48fd-912f-dda6c8df5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response format-JSON schema\n",
    "response_format_json = {\n",
    "  \"type\": \"json_schema\",\n",
    "  \"json_schema\": {\n",
    "    \"name\": \"Top10BestSellingBooks\",\n",
    "    \"strict\": True,\n",
    "    \"schema\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"Top10BestSellingBooks\": {\n",
    "          \"type\": \"array\",\n",
    "          \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"title\": { \"type\": \"string\" },\n",
    "              \"author\": { \"type\": \"string\" },\n",
    "              \"yearPublished\": { \"type\": \"integer\" },\n",
    "              \"summary\": { \"type\": \"string\" }\n",
    "            },\n",
    "            \"required\": [\"title\", \"author\", \"yearPublished\", \"summary\"],\n",
    "            \"additionalProperties\": False\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"Top10BestSellingBooks\"],\n",
    "      \"additionalProperties\": False\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1703d0c-ae6c-4fdf-bfed-f4c2138de1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Give me the names of the 10 best-selling books, their authors, the year they were published, and a concise summary in JSON format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e554cd62-b8d2-491f-8f0c-9fa030502455",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant designed to output information exclusively in JSON format.\n",
    "### Example JSON Format\n",
    "{\n",
    "  \"Top10BestSellingBooks\": [\n",
    "    {\n",
    "      \"title\": \"Book Title\",\n",
    "      \"author\": \"Author Name\",\n",
    "      \"yearPublished\": \"Year\",\n",
    "      \"summary\": \"Brief summary of the book.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6dddc6-150b-4301-bd0c-136a68a6c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47e66ee8-bca1-46bd-9b73-0078ed5df955",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  temperature = 0,\n",
    "  response_format=response_format_json,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\":system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7d02604-40bb-4bb5-b09f-f5897f8d472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Top10BestSellingBooks\":[{\"title\":\"Don Quixote\",\"author\":\"Miguel de Cervantes\",\"yearPublished\":1605,\"summary\":\"A Spanish novel about the adventures of a nobleman who reads so many chivalric romances that he loses his sanity and decides to become a knight-errant.\"},{\"title\":\"A Tale of Two Cities\",\"author\":\"Charles Dickens\",\"yearPublished\":1859,\"summary\":\"A historical novel set in London and Paris before and during the French Revolution, focusing on themes of resurrection and transformation.\"},{\"title\":\"The Lord of the Rings\",\"author\":\"J.R.R. Tolkien\",\"yearPublished\":1954,\"summary\":\"An epic fantasy novel that follows the quest to destroy the One Ring and defeat the Dark Lord Sauron.\"},{\"title\":\"The Little Prince\",\"author\":\"Antoine de Saint-Exupéry\",\"yearPublished\":1943,\"summary\":\"A philosophical tale about a young prince who travels from planet to planet, exploring themes of loneliness, friendship, and love.\"},{\"title\":\"Harry Potter and the Philosopher\\'s Stone\",\"author\":\"J.K. Rowling\",\"yearPublished\":1997,\"summary\":\"The first book in the Harry Potter series, introducing Harry as he discovers his magical heritage and attends Hogwarts School of Witchcraft and Wizardry.\"},{\"title\":\"The Hobbit\",\"author\":\"J.R.R. Tolkien\",\"yearPublished\":1937,\"summary\":\"A fantasy novel about the journey of Bilbo Baggins, a hobbit who is reluctantly drawn into an epic quest to reclaim a treasure guarded by a dragon.\"},{\"title\":\"And Then There Were None\",\"author\":\"Agatha Christie\",\"yearPublished\":1939,\"summary\":\"A mystery novel about ten strangers invited to an isolated island, where they are killed one by one.\"},{\"title\":\"Dream of the Red Chamber\",\"author\":\"Cao Xueqin\",\"yearPublished\":1791,\"summary\":\"A Chinese novel that provides a detailed, episodic record of the lives of two branches of a large, aristocratic family.\"},{\"title\":\"The Lion, the Witch and the Wardrobe\",\"author\":\"C.S. Lewis\",\"yearPublished\":1950,\"summary\":\"The first published book in The Chronicles of Narnia series, where four children enter a magical world through a wardrobe.\"},{\"title\":\"The Da Vinci Code\",\"author\":\"Dan Brown\",\"yearPublished\":2003,\"summary\":\"A mystery thriller that follows symbologist Robert Langdon and cryptologist Sophie Neveu as they investigate a murder in Paris\\'s Louvre Museum.\"}]}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "327c0040-8ab9-422a-9fe0-8b03688833a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Top10BestSellingBooks\":[{\"title\":\"Don Quixote\",\"author\":\"Miguel de Cervantes\",\"yearPublished\":1605,\"summary\":\"A Spanish novel about the adventures of a nobleman who reads so many chivalric romances that he loses his sanity and decides to become a knight-errant.\"},{\"title\":\"A Tale of Two Cities\",\"author\":\"Charles Dickens\",\"yearPublished\":1859,\"summary\":\"A historical novel set in London and Paris before and during the French Revolution, focusing on themes of resurrection and transformation.\"},{\"title\":\"The Lord of the Rings\",\"author\":\"J.R.R. Tolkien\",\"yearPublished\":1954,\"summary\":\"An epic fantasy novel that follows the quest to destroy the One Ring and defeat the Dark Lord Sauron.\"},{\"title\":\"The Little Prince\",\"author\":\"Antoine de Saint-Exupéry\",\"yearPublished\":1943,\"summary\":\"A philosophical tale about a young prince who travels from planet to planet, exploring themes of loneliness, friendship, and love.\"},{\"title\":\"Harry Potter and the Philosopher's Stone\",\"author\":\"J.K. Rowling\",\"yearPublished\":1997,\"summary\":\"The first book in the Harry Potter series, introducing Harry as he discovers his magical heritage and attends Hogwarts School of Witchcraft and Wizardry.\"},{\"title\":\"The Hobbit\",\"author\":\"J.R.R. Tolkien\",\"yearPublished\":1937,\"summary\":\"A fantasy novel about the journey of Bilbo Baggins, a hobbit who is reluctantly drawn into an epic quest to reclaim a treasure guarded by a dragon.\"},{\"title\":\"And Then There Were None\",\"author\":\"Agatha Christie\",\"yearPublished\":1939,\"summary\":\"A mystery novel about ten strangers invited to an isolated island, where they are killed one by one.\"},{\"title\":\"Dream of the Red Chamber\",\"author\":\"Cao Xueqin\",\"yearPublished\":1791,\"summary\":\"A Chinese novel that provides a detailed, episodic record of the lives of two branches of a large, aristocratic family.\"},{\"title\":\"The Lion, the Witch and the Wardrobe\",\"author\":\"C.S. Lewis\",\"yearPublished\":1950,\"summary\":\"The first published book in The Chronicles of Narnia series, where four children enter a magical world through a wardrobe.\"},{\"title\":\"The Da Vinci Code\",\"author\":\"Dan Brown\",\"yearPublished\":2003,\"summary\":\"A mystery thriller that follows symbologist Robert Langdon and cryptologist Sophie Neveu as they investigate a murder in Paris's Louvre Museum.\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7e97e53-5f9b-4309-b767-5d3514980ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_book = json.loads(json_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2582b79a-dbf5-4d53-b46e-5ce825bd744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top10BestSellingBooks': [{'author': 'Miguel de Cervantes',\n",
      "                            'summary': 'A Spanish novel about the adventures '\n",
      "                                       'of a nobleman who reads so many '\n",
      "                                       'chivalric romances that he loses his '\n",
      "                                       'sanity and decides to become a '\n",
      "                                       'knight-errant.',\n",
      "                            'title': 'Don Quixote',\n",
      "                            'yearPublished': '1605'},\n",
      "                           {'author': 'Charles Dickens',\n",
      "                            'summary': 'A historical novel set in London and '\n",
      "                                       'Paris before and during the French '\n",
      "                                       'Revolution, focusing on themes of '\n",
      "                                       'resurrection and transformation.',\n",
      "                            'title': 'A Tale of Two Cities',\n",
      "                            'yearPublished': '1859'},\n",
      "                           {'author': 'J.R.R. Tolkien',\n",
      "                            'summary': 'An epic fantasy novel that follows the '\n",
      "                                       'quest to destroy the One Ring and '\n",
      "                                       'defeat the Dark Lord Sauron.',\n",
      "                            'title': 'The Lord of the Rings',\n",
      "                            'yearPublished': '1954'},\n",
      "                           {'author': 'Antoine de Saint-Exupéry',\n",
      "                            'summary': 'A philosophical tale about a young '\n",
      "                                       'prince who travels from planet to '\n",
      "                                       'planet, learning about life and human '\n",
      "                                       'nature.',\n",
      "                            'title': 'The Little Prince',\n",
      "                            'yearPublished': '1943'},\n",
      "                           {'author': 'J.K. Rowling',\n",
      "                            'summary': 'The first book in the Harry Potter '\n",
      "                                       'series, introducing the young wizard '\n",
      "                                       'Harry Potter and his adventures at '\n",
      "                                       'Hogwarts School of Witchcraft and '\n",
      "                                       'Wizardry.',\n",
      "                            'title': \"Harry Potter and the Philosopher's Stone\",\n",
      "                            'yearPublished': '1997'},\n",
      "                           {'author': 'J.R.R. Tolkien',\n",
      "                            'summary': 'A fantasy novel about the journey of '\n",
      "                                       'Bilbo Baggins, a hobbit who is '\n",
      "                                       'reluctantly drawn into an epic quest '\n",
      "                                       'to reclaim a treasure guarded by a '\n",
      "                                       'dragon.',\n",
      "                            'title': 'The Hobbit',\n",
      "                            'yearPublished': '1937'},\n",
      "                           {'author': 'Agatha Christie',\n",
      "                            'summary': 'A mystery novel about ten strangers '\n",
      "                                       'who are invited to an isolated island, '\n",
      "                                       'where they are killed one by one.',\n",
      "                            'title': 'And Then There Were None',\n",
      "                            'yearPublished': '1939'},\n",
      "                           {'author': 'Cao Xueqin',\n",
      "                            'summary': 'A Chinese novel that provides a '\n",
      "                                       'detailed, episodic record of the lives '\n",
      "                                       'of two branches of the wealthy and '\n",
      "                                       'aristocratic Jia clan.',\n",
      "                            'title': 'Dream of the Red Chamber',\n",
      "                            'yearPublished': '1791'},\n",
      "                           {'author': 'C.S. Lewis',\n",
      "                            'summary': 'A fantasy novel about four siblings '\n",
      "                                       'who discover a magical land called '\n",
      "                                       'Narnia, which is under the spell of an '\n",
      "                                       'evil witch.',\n",
      "                            'title': 'The Lion, the Witch and the Wardrobe',\n",
      "                            'yearPublished': '1950'},\n",
      "                           {'author': 'Dan Brown',\n",
      "                            'summary': 'A mystery thriller that follows '\n",
      "                                       'symbologist Robert Langdon and '\n",
      "                                       'cryptologist Sophie Neveu as they '\n",
      "                                       'investigate a murder in the Louvre '\n",
      "                                       'Museum.',\n",
      "                            'title': 'The Da Vinci Code',\n",
      "                            'yearPublished': '2003'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(result_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38e639fc-2f7d-4c90-8154-b1454d158ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Miguel de Cervantes',\n",
      " 'summary': 'A Spanish novel about the adventures of a nobleman who reads so '\n",
      "            'many chivalric romances that he loses his sanity and decides to '\n",
      "            'become a knight-errant.',\n",
      " 'title': 'Don Quixote',\n",
      " 'yearPublished': '1605'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(result_book['Top10BestSellingBooks'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46f808-3584-44a1-a0ba-7af7d73f37ef",
   "metadata": {},
   "source": [
    "### Using Pydantic to define the output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfca7c91-fcd9-4238-8588-f80fb608fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structured output scheme.\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    yearPublished: int\n",
    "    summary: str\n",
    "\n",
    "class Top10BestSellingBooks(BaseModel):\n",
    "    books: List[Book]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb0360bd-9dba-4926-be9a-e7376433b07b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$defs': {'Book': {'properties': {'title': {'title': 'Title',\n",
       "     'type': 'string'},\n",
       "    'author': {'title': 'Author', 'type': 'string'},\n",
       "    'yearPublished': {'title': 'Yearpublished', 'type': 'integer'},\n",
       "    'summary': {'title': 'Summary', 'type': 'string'}},\n",
       "   'required': ['title', 'author', 'yearPublished', 'summary'],\n",
       "   'title': 'Book',\n",
       "   'type': 'object'}},\n",
       " 'items': {'$ref': '#/$defs/Book'},\n",
       " 'type': 'array'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta = TypeAdapter(List[Book])\n",
    "schema = ta.json_schema(mode='validation')\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e2cae-6078-46fb-8885-1d642076cd15",
   "metadata": {},
   "source": [
    "## Extracting data from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b81c111-e392-4926-a429-043d752b3042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papersDatasetPath: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset\n",
      "pdfDirectory:      /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper\n"
     ]
    }
   ],
   "source": [
    "assert TAI_DATASET_ROOT_ENV_VAR in os.environ\n",
    "papersDatasetPath= os.path.join(os.environ[TAI_DATASET_ROOT_ENV_VAR],'papers_dataset')\n",
    "pdfDirectory= os.path.join( papersDatasetPath,'rag_research_paper')\n",
    "\n",
    "print(f'papersDatasetPath: {papersDatasetPath}')\n",
    "print(f'pdfDirectory:      {pdfDirectory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56fc6d7c-a79d-41fc-bdc5-3c3098af53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(papersDatasetPath):\n",
    "    print(f'The dataset at {papersDatasetPath} does not exist. Downloading it..')\n",
    "    file_path = hf_hub_download(repo_id=\"jaiganesan/ai_tutor_knowledge\", filename=\"rag_research_paper.zip\",repo_type=\"dataset\",local_dir=papersDatasetPath)\n",
    "\n",
    "assert os.path.exists(papersDatasetPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e435a9ae-e8a4-44c3-8ab0-84f099c55c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper.zip\n",
      "   creating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/\n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2405.07437v2.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2407.01219v1.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2407.07858v1.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2407.08223v1.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2407.16833v1.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2407.21712v1.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2408.08067v2.pdf  \n",
      "  inflating: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2408.08921v1.pdf  \n"
     ]
    }
   ],
   "source": [
    "!unzip ${TAI_DATASET_ROOT}/papers_dataset/rag_research_paper.zip -d ${TAI_DATASET_ROOT}/papers_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6e2509a-9f26-4a31-b569-c72f8fa12d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pdf_path: /home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/rag_research_paper/2407.07858v1.pdf\n",
      "  Page 0:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-001.png\n",
      "  Page 1:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-002.png\n",
      "  Page 2:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-003.png\n",
      "  Page 3:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-004.png\n",
      "  Page 4:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-005.png\n",
      "  Page 5:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-006.png\n",
      "  Page 6:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-007.png\n",
      "  Page 7:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-008.png\n",
      "['/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-001.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-002.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-003.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-004.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-005.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-006.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-007.png', '/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-008.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "outputDir= os.path.join( papersDatasetPath,'pages')\n",
    "os.makedirs( outputDir, exist_ok=True)\n",
    "\n",
    "pages_png = []\n",
    "\n",
    "for pdf_file in os.listdir(pdfDirectory):\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join( pdfDirectory, pdf_file)\n",
    "        print(f'pdf_path: {pdf_path}')\n",
    "\n",
    "        convert = convert_from_path(pdf_path, use_pdftocairo=True)\n",
    "\n",
    "        pdf_output_dir = os.path.join( outputDir, os.path.splitext(pdf_file)[0])\n",
    "        os.makedirs(pdf_output_dir, exist_ok=True)\n",
    "\n",
    "        for page_num, image in enumerate(convert):\n",
    "            page_filename = f\"page-{str(page_num + 1).zfill(3)}.png\"\n",
    "            full_path = os.path.join(pdf_output_dir, page_filename)\n",
    "            print(f'  Page {page_num}:{full_path}')\n",
    "            image.save(full_path)\n",
    "\n",
    "            pages_png.append(full_path)\n",
    "\n",
    "print(pages_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfddbfad-abaa-4f03-b79c-0cad12c1e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to base64 encode an image.\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import json\n",
    "\n",
    "# Function to encode the image\n",
    "\n",
    "def encode_image(image_path):\n",
    "\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d744d9b-dd2b-4cc9-b243-16e1bbc79b11",
   "metadata": {},
   "source": [
    "### Json Schema of the structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a8e6a6-97d3-4a6c-ab9e-52afb787f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response format- JSON schema\n",
    "json_response_format = {\n",
    "  \"type\": \"json_schema\",\n",
    "  \"json_schema\": {\n",
    "    \"name\": \"research_paper_data\",\n",
    "    \"strict\": True,\n",
    "    \"schema\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"research_paper_data\": {\n",
    "          \"type\": \"array\",\n",
    "          \"items\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"name\": { \"type\": \"string\" },\n",
    "                \"source\": { \"type\": \"string\" },\n",
    "                \"content\": { \"type\": \"string\"}\n",
    "            },\n",
    "\n",
    "            \"required\": [\"name\", \"source\", \"content\"],\n",
    "            \"additionalProperties\": False\n",
    "          }\n",
    "        },\n",
    "      },\n",
    "      \"required\": [\"research_paper_data\"],\n",
    "      \"additionalProperties\": False\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4120eb8-20fa-4a9b-8ec5-d05b82a33843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "system_instruction_prompt =\"\"\"\n",
    "You are an expert in extracting structured data from research paper images.\n",
    "\n",
    "Task Description:\n",
    "Extract comprehensive information from PDF research paper images, including all headlines, content, and visual elements.\n",
    "Preserve complete information without fragmentation.\n",
    "\n",
    "Must Follow Guidenline: Extract all text and information accurately from each image provided. Organize content into multiple\n",
    "JSON objects when appropriate, based on the amount and type of content. Each JSON should clearly reflect distinct content\n",
    "sections for streamlined analysis\n",
    "\n",
    "Content Requirements:\n",
    "1. Missing Headlines\n",
    "- If no visible headline exists, generate appropriate ones based on content\n",
    "- Group related content under these generated headlines\n",
    "\n",
    "2. Visual Elements\n",
    "For figures, graphs, tables, and architectures:\n",
    "- Extract title/caption\n",
    "- Describe main trends and comparisons\n",
    "- Detail architecture designs\n",
    "- Include related insights from surrounding text\n",
    "\n",
    "3. Text Processing\n",
    "- Extract complete sentences without summarization\n",
    "- Maintain original detail level\n",
    "- Merge fragmented content logically\n",
    "- Preserve all technical information\n",
    "\n",
    "Required output Format (JSON):\n",
    "[\n",
    "{\n",
    "    \"source\": \"Extract complete arXiv ID including prefix (e.g., arXiv:2405.07437v2).\n",
    "               Verify ID accuracy multiple times. if there is no Arxiv ID return None\",\n",
    "\n",
    "    \"name\": \"Extract or generate all headlines and subheadlines (e.g., Abstract,\n",
    "            Introduction, Methods, etc). Include section titles and subsection headings.\",\n",
    "\n",
    "    \"content\": \"For each section:\n",
    "                - Complete text content\n",
    "                - Visual element descriptions\n",
    "                - Figure/graph details:\n",
    "                  * Title/caption\n",
    "                  * Description\n",
    "                  * Key trends/comparisons\n",
    "                  * Architecture details\n",
    "                  * Related insights\"\n",
    "},\n",
    "]\n",
    "\n",
    "Key Guidelines:\n",
    "- Extract exact content without summarization\n",
    "- Ensure accuracy in complex technical details\n",
    "- Maintain logical content organization\n",
    "- Include complete visual element analysis\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d0037ee-89e5-436d-b55e-b0ea7c72f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import re\n",
    "\n",
    "def arxiv_extraction(arxiv_id):\n",
    "  client = arxiv.Client()\n",
    "  search = arxiv.Search(id_list=re.findall(r'(\\d{4}\\.\\d{5}|\\w+(?:-\\w+)?/\\d{7})', arxiv_id), max_results=1)\n",
    "  results = client.results(search)\n",
    "\n",
    "  for result in results:\n",
    "    return result.title, result.pdf_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adeb935e-7820-4fef-b77a-c50ccaf1aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-001.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-002.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-003.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-004.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-005.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-006.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-007.png\n",
      "page:/home/minguzzi/repo/towards_ai_course/dataset/papers_dataset/pages/2407.07858v1/page-008.png\n"
     ]
    }
   ],
   "source": [
    "# Extracts data using OpenAI\n",
    "\n",
    "import json\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "desc = []\n",
    "\n",
    "\n",
    "for page in pages_png:\n",
    "  # Getting the base64\n",
    "  base64_image = encode_image(page)\n",
    "  print(f'page:{page}')\n",
    "\n",
    "  try:\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        response_format = json_response_format,\n",
    "        temperature = 0,\n",
    "        messages= [\n",
    "              {\"role\": \"system\",\"content\":system_instruction_prompt},\n",
    "              {\"role\": \"user\",\"content\": [{\"type\": \"text\", \"text\": \"Extract the content from this research paper image.\"},\n",
    "                                          {\"type\": \"image_url\",\"image_url\": {\"url\":f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                                                                              \"detail\": \"high\"}}\n",
    "                                          ]\n",
    "                  }\n",
    "                  ],\n",
    "      )\n",
    "\n",
    "    if response.choices[0].message.content is None:\n",
    "      continue\n",
    "\n",
    "    result = json.loads(response.choices[0].message.content)\n",
    "\n",
    "    if 'page-001' in page:\n",
    "      # Or You can use the Image path to extract the Arxiv Research paper ID.\n",
    "      research_paper_id = result['research_paper_data'][0]['source']\n",
    "      research_paper_title, research_paper_url = arxiv_extraction(research_paper_id)\n",
    "\n",
    "      for i in range(len(result['research_paper_data'])):\n",
    "        result['research_paper_data'][i]['source'] = research_paper_id\n",
    "        result['research_paper_data'][i]['name'] = research_paper_title +\":\"+ result['research_paper_data'][i]['name']\n",
    "        result['research_paper_data'][i]['url'] = research_paper_url\n",
    "\n",
    "    if 'page-001' not in page:\n",
    "      for i in range(len(result['research_paper_data'])):\n",
    "        result['research_paper_data'][i]['source'] = research_paper_id\n",
    "        result['research_paper_data'][i]['name'] = research_paper_title +\":\"+ result['research_paper_data'][i]['name']\n",
    "        result['research_paper_data'][i]['url'] = research_paper_url\n",
    "\n",
    "    desc.extend(result['research_paper_data'])\n",
    "\n",
    "  except Exception as e:\n",
    "    print(response.choices[0].finish_reason)\n",
    "    print(f\"Skipping {page}... error: {e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f2f8094-a60d-4c8a-8b2c-837ff12f16b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content research paper title and Headline : FACTS About Building Retrieval Augmented Generation-based Chatbots:FACTS About Building Retrieval Augmented Generation-based Chatbots \n",
      "\n",
      "Content : Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Jayjya, Ashok Maram, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigaichalam, Tamar Bar, Sanjana Krishnan, Jasmine Jaksic, Nave Aligarci, Jacob Liberman, Joey Conway, Sonu Nayyar and Justin Boitano\n",
      "NVIDIA\n",
      "{rakkiraju,anbangx,dbora}@nvidia.com\n",
      "\n",
      "ABSTRACT\n",
      "Enterprise chatbots, powered by generative AI, are rapidly emerging as the most explored initial applications of this technology in the industry, aimed at enhancing employee productivity. Retrieval Augmented Generation (RAG), Large Language Models (LLMs), Langchain/Llamaindex types of LLM orchestration frameworks serve as key technological components in building generative-AI based chatbots. However, building successful enterprise chatbots is not easy. They require meticulous engineering of RAG pipelines. This includes fine-tuning semantic embeddings and LLMs, extracting relevant documents from vector databases, rephrasing queries, reranking results, providing effective prompting, honoring document access controls, providing concise responses, including pertinent references, safeguarding personal information, and building systems to orchestrate all these activities. In this paper, we present a framework for building effective RAG-based chatbots based on our firsthand experience of building three chatbots at NVIDIA: chatbots for HR and IT benefits, company financial earnings, and general enterprise content. Our contributions in this paper are three-fold. First, we introduce our FACTS framework for building enterprise-grade RAG-based chatbots that address the challenges mentioned. FACTS mnemonic refers to the five dimensions that RAG-based chatbots must get right - namely content freshness (F), architectures(A), cost economics of LLMs (C), testing (T), and security (S). Second, we present fifteen control points of RAG pipelines and techniques for optimizing chatbots’ performance at each stage. Finally, we present empirical results from our enterprise data on the accuracy-efficiency tradeoffs between large LLMs vs small LLMs. To the best of our knowledge, this is the first paper of its kind that provides a holistic view of the factors as well as solutions for building secure enterprise-grade chatbots.\n",
      "\n",
      "1 INTRODUCTION\n",
      "Chatbots are increasingly becoming an extension of search tools in companies for finding relevant information. Whether it is HR benefits, IT help, sales queries, or engineering issues, enterprise chatbots are now go-to productivity tools. Before the debut of OpenAI’s Chat-GPT [2] in November 2022, companies relied on internally developed chatbots based on dialog flows. Such bots required extensive training for intent understanding and meticulous orchestration for response generation and yet could only provide extractive answers at best. These early bots, built on dialog management systems paired with information retrieval and question answering (IRQA) solutions were fragile and limited in capability. While previous generation language models and GPT models existed, they lacked the accuracy, robustness, and reliability needed for broad enterprise use [5].\n",
      "Chat-GPT’s release, the emergence of vector databases, and the wide-spread use of retrieval augmented generation (RAGs) [8] marked the beginning of a new era in Chatbot domain. Now, LLMs can understand user intents with simple prompts in natural language, eliminating the need for complex intent variant training, synthesizing enterprise content coherently, thereby empowering chatbots with conversational capability beyond scripted intent recognition. While LLMs bring their generative capabilities to construct coherent, factual, and logical responses to user queries, vector database-powered information retrieval (IR) systems augment LLMs ability to retrieve fresh content. Tools like LangChain [1] and LlamaIndex [6] facilitate chatbot construction, and orchestration of complex workflows including memory, agents, prompt templates, and overall flow. Together, vector-search based IR systems, LLMs, and LangChain-like frameworks form core components of a RAG pipeline that power growing generative AI chatbots in post Chat-GPT era.\n",
      "At NVIDIA, our main motivation was to improve our employee productivity by building enterprise chatbots. Our initial enthusiasm quickly met with the reality of addressing numerous challenges. We learned that crafting a successful enterprise chatbot, even in post Chat-GPT era, while promising, is not easy. The process demands meticulous engineering of RAG pipelines, fine-tuning LLMs, and engineering prompts, ensuring relevancy and accuracy of enterprise knowledge, honoring document access control permissions, providing concise responses, including pertinent references, and safeguarding personal information. All of these require careful design, skillful execution, and thorough evaluation demanding many iterations. Additionally, maintaining user engagement while optimizing for speed and cost-efficiency is essential. Through our journey, we learned that getting an enterprise conversational virtual assistant right is akin to achieving a perfect symphony where every note carries significance!\n",
      "In this paper, we share our experiences and strategies in building effective, secure, and cost-efficient chatbots. We answer the following questions from a practitioner perspective: \n",
      "\n",
      "Source : arXiv:2407.07858v1 [cs.LG] 10 Jul 2024 \n",
      "\n",
      "URL : http://arxiv.org/pdf/2407.07858v1\n"
     ]
    }
   ],
   "source": [
    "print(\"Content research paper title and Headline :\",desc[0]['name'],\"\\n\")\n",
    "print(\"Content :\",desc[0]['content'],\"\\n\")\n",
    "print(\"Source :\",desc[0]['source'],\"\\n\")\n",
    "print(\"URL :\",desc[0]['url'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0956985-c4de-4450-b32e-9b3bc4df2f97",
   "metadata": {},
   "source": [
    "# Downloading the full dataset for the next steps of the course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ef830a8-2de5-45b0-ae87-611f10c54508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiTutorDatasetFilePath: /home/minguzzi/repo/towards_ai_course/dataset/ai_tutor_knowledge.jsonl\n"
     ]
    }
   ],
   "source": [
    "assert TAI_DATASET_ROOT_ENV_VAR in os.environ\n",
    "aiTutorDatasetFilePath= os.path.join(os.environ[TAI_DATASET_ROOT_ENV_VAR],'ai_tutor_knowledge.jsonl')\n",
    "\n",
    "print(f'aiTutorDatasetFilePath: {aiTutorDatasetFilePath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f1a165a-333c-420c-a4f3-9662a83bc2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:  BERT HuggingFace Model Deployment using Kubernetes [ Github Repo]  03/07/2024\n",
      "Content:  Github Repo : https://github.com/vaibhawkhemka/ML-Umbrella/tree/main/MLops/Model_Deployment/Bert_Kubernetes_deployment   Model development is useless if you dont deploy it to production  which comes with a lot of issues of scalability and portability.   I have deployed a basic BERT model from the huggingface transformer on Kubernetes with the help of docker  which will give a feel of how to deploy and manage pods on production.   Model Serving and Deployment:ML Pipeline:Workflow:   Model server (using FastAPI  uvicorn) for BERT uncased model    Containerize model and inference scripts to create a docker image    Kubernetes deployment for these model servers (for scalability)  Testing   Components:Model serverUsed BERT uncased model from hugging face for prediction of next word [MASK]. Inference is done using transformer-cli which uses fastapi and uvicorn to serve the model endpoints   Server streaming:   Testing: (fastapi docs)   http://localhost:8888/docs/   { output: [ { score: 0.21721847355365753  token: 2204  token_str: good  sequence: today is a good day }  { score: 0.16623663902282715  token: 2047  token_str: new  sequence: today is a new day }  { score: 0.07342924177646637  token: 2307  token_str: great  sequence: today is a great day }  { score: 0.0656224861741066  token: 2502  token_str: big  sequence: today is a big day }  { score: 0.03518620505928993  token: 3376  token_str: beautiful  sequence: today is a beautiful day } ]   ContainerizationCreated a docker image from huggingface GPU base image and pushed to dockerhub after testing.   Testing on docker container:   You can directly pull the image vaibhaw06/bert-kubernetes:latest   K8s deploymentUsed minikube and kubectl commands to create a single pod container for serving the model by configuring deployment and service config   deployment.yaml   apiVersion: apps/v1 kind: Deployment metadata: name: bert-deployment labels: app: bertapp spec: replicas: 1 selector: matchLabels: app: bertapp template: metadata: labels: app: bertapp spec: containers: - name: bertapp image: vaibhaw06/bert-kubernetes ports: - containerPort: 8080 --- apiVersion: v1 kind: Service metadata: name: bert-service spec: type: NodePort selector: app: bertapp ports: - protocol: TCP port: 8080 targetPort: 8080 nodePort: 30100Setting up minikube and running pods using kubectl and deployment.yaml   minikube start kubectl apply -f deployment.yamlFinal Testing:kubectl get allIt took around 15 mins to pull and create container pods.   kubectl image listkubectl get svcminikube service bert-serviceAfter running the last command minikube service bert-service  you can verify the resulting deployment on the web endpoint.   Find the GitHub Link: https://github.com/vaibhawkhemka/ML-Umbrella/tree/main/MLops/Model_Deployment/Bert_Kubernetes_deployment   If you have any questions  ping me on my LinkedIn: https://www.linkedin.com/in/vaibhaw-khemka-a92156176/   Follow ML Umbrella for more such detailed  actionable projects.   Future Extension:Scaling with pod replicas and load balancer -   Self-healing\n",
      "URL:  https://towardsai.net/p/machine-learning/bert-huggingface-model-deployment-using-kubernetes-github-repo-03-07-2024\n",
      "Source:  tai_blog\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset from Huggingface hub\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "\n",
    "file_path = hf_hub_download(repo_id=\"jaiganesan/ai_tutor_knowledge\", filename=\"ai_tutor_knowledge.jsonl\", repo_type=\"dataset\")\n",
    "\n",
    "# Exploring the dataset content\n",
    "with open(file_path, \"r\") as inFile:\n",
    "    ai_tutor_knowledge = [json.loads(line) for line in inFile]\n",
    "    \n",
    "with open(file_path, \"r\") as inFile:        \n",
    "    with open(aiTutorDatasetFilePath,'w') as outFile:   \n",
    "        outFile.write( inFile.read())\n",
    "        \n",
    "print(\"Title: \", ai_tutor_knowledge[0]['name'])\n",
    "print(\"Content: \", ai_tutor_knowledge[0]['content'])\n",
    "print(\"URL: \", ai_tutor_knowledge[0]['url'])\n",
    "print(\"Source: \", ai_tutor_knowledge[0]['source'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
