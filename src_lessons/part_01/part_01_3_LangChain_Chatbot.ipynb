{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faea30ca-3a60-4dfd-9c17-aa5822db3fc9",
   "metadata": {},
   "source": [
    "# Builds a LangChain chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8641e798-afa2-402c-a8a8-c6c81a9bb442",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import gradio as gr\n",
    "import logging as log\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a35e61ec-9390-4209-9b49-e3fbbe61cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.INFO, format='%(asctime)s [%(levelname)5s] %(message)s',datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acd5472c-f3e2-4df0-8233-8617673beb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(model:LlmModel.GeminiFlash, vendor:LlmVendor.Google, envVar:GOOGLE_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class LlmVendor( enum.Enum):\n",
    "    Google=1,\n",
    "    OpenAI=2\n",
    "\n",
    "class LlmModel( enum.Enum):\n",
    "    GeminiFlash=1,\n",
    "    GeminiPro=2\n",
    "    OpenAI=3\n",
    "    \n",
    "class LlmModelFactory():\n",
    "    def __init__(self, model: LlmModel, vendor: LlmVendor, envVar:str):\n",
    "        self._model = model\n",
    "        self._vendor= vendor\n",
    "        self._envVar= envVar\n",
    "\n",
    "        if not envVar in os.environ:\n",
    "            raise ValueError(f'{envVar} not found in the environment.')\n",
    "\n",
    "    @staticmethod\n",
    "    def createGoogleGeminiFlash(): \n",
    "        return LlmModelFactory(model= LlmModel.GeminiFlash,  \n",
    "                               vendor= LlmVendor.Google,\n",
    "                               envVar='GOOGLE_API_KEY')\n",
    "    @staticmethod\n",
    "    def modelName( llmModel: LlmModel):\n",
    "        match llmModel:\n",
    "            case LlmModel.GeminiFlash:\n",
    "                return \"gemini-1.5-flash\"\n",
    "            case LlmModel.GeminiPro:     \n",
    "                return \"gemini-1.5-pro\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'(model:{self._model}, vendor:{self._vendor}, envVar:{self._envVar})'\n",
    "\n",
    "    def createChatModel(self, \n",
    "                       maxOutputTokens=250,\n",
    "                       temperature=0.0):\n",
    "        match self._vendor:\n",
    "            case LlmVendor.Google:\n",
    "                return ChatGoogleGenerativeAI(model= LlmModelFactory.modelName(self._model), \n",
    "                                              max_output_tokens=maxOutputTokens, \n",
    "                                              temperature=temperature)\n",
    "                \n",
    "\n",
    "llmModelFactory= LlmModelFactory.createGoogleGeminiFlash()\n",
    "print(llmModelFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bc2be1-8141-43b8-a6ad-69cdaf491582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = llmModelFactory.createChatModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "783e2124-d608-4530-9467-ee3752c6ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [('system','You are a helpful assistant. That can translate from English to {language}'),\n",
    "           ('human','Translate the following text:\\n{text}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d216318-adc0-4d1f-873f-deb54a0abb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ChatPromptTemplate(messages) | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f47bf4-335f-4c81-b2cf-a5a843bdd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= chain.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6c60e61-299f-496e-93a1-5073a7539be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce6b8f-757c-4594-af23-8009c7235300",
   "metadata": {},
   "source": [
    "## Other test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b7ef4f-c975-4a96-8831-31e3dce394b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainModelToParser = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19cbc9f5-008d-4d65-a5b5-2c068b87e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [('system','You are a helpful assistant. That can translate from English to {language}'),\n",
    "           ('human','Translate the following text:\\n{text}')]\n",
    "promptTemplate= ChatPromptTemplate(messages)\n",
    "chain= promptTemplate | chainModelToParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6f98953-6c91-4636-b6f9-018fd0f9b500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you?  translates to:\\n\\n**Come stai?** (informal, singular)  or  **Come state?** (formal, singular or plural)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result= chain.invoke({\"language\": \"Italian\", \"text\": \"How are you?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf40b4d9-05c4-4199-9709-f8f5c9f155c4",
   "metadata": {},
   "source": [
    "# Chatbot. It runs until the user types 'quit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb56702f-236a-485f-ac0e-2f6914d087e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:   system\n",
      "Message:You are a polite and helpful assistant.\n",
      "\n",
      "Enter the next prompt. quit to terminate:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    }
   ],
   "source": [
    "messages= [('system','You are a polite and helpful assistant.')]\n",
    "chainModelToParser = model | StrOutputParser()\n",
    "\n",
    "while True:\n",
    "    for (role,message) in messages:\n",
    "        print(f'Role:   {role}')\n",
    "        print(f'Message:{message}\\n')\n",
    "    print('Enter the next prompt. quit to terminate:')\n",
    "    userPrompt= input()\n",
    "    if 'quit'==userPrompt.strip().lower():\n",
    "        break\n",
    "    messages.append( ('human',userPrompt))  \n",
    "    promptTemplate= ChatPromptTemplate(messages)\n",
    "    chain= promptTemplate | chainModelToParser\n",
    "    result= chain.invoke({})\n",
    "    print(result)\n",
    "    messages.append( ('ai',result))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224104c8-2031-49b5-b324-ce9638065030",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "## Same chatbot, but with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54b8ce7e-a6a3-4138-8c55-a3edede03f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:35:06 [ INFO] HTTP Request: GET http://127.0.0.1:7870/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "10:35:06 [ INFO] HTTP Request: HEAD http://127.0.0.1:7870/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:35:06 [ INFO] HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "messages= [('system','You are a polite and helpful assistant.')]\n",
    "chainModelToParser = model | StrOutputParser()\n",
    "chatHistory=[]\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "def chatBot( userPrompt):\n",
    "    global chatHistory\n",
    "    global messages\n",
    "    \n",
    "    errMessage = str()\n",
    "    try:\n",
    "        messages.append( ('human',userPrompt))  \n",
    "        \n",
    "        for (role,message) in messages:\n",
    "            log.info(f'Role:{role} {message}')\n",
    "        \n",
    "        promptTemplate= ChatPromptTemplate(messages)\n",
    "        chain= promptTemplate | chainModelToParser\n",
    "        result= chain.invoke({})\n",
    "        messages.append( ('ai',result))  \n",
    "        \n",
    "        chatHistory = [ f'{role}: {message}' for (role,message) in messages]\n",
    "        textChatHistory= '\\n'.join(chatHistory)\n",
    "        return (result, textChatHistory, errMessage)\n",
    "        \n",
    "        \n",
    "    except Exception as exc:\n",
    "        log.error(f'Exception detected:{exc}')\n",
    "        return (\"\", textChatHistory, str(exc))\n",
    "\n",
    "chatbotUi = gr.Interface(fn=chatBot, \n",
    "                        inputs=[gr.Textbox(label='User Prompt', show_label=True, lines=5)],\n",
    "                        outputs=[gr.Textbox(label='LLM Response', show_label=True),\n",
    "                                gr.Textbox(label='Chat History', show_label=True,lines=10),\n",
    "                                gr.Textbox(label='Error', show_label=True)],\n",
    "                        title='Chatbot',\n",
    "                        flagging_mode='never')\n",
    "chatbotUi.launch()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1bee52a-692c-4dea-9be9-b40d6e7bcaa5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:04:17 [ INFO] HTTP Request: GET http://127.0.0.1:7862/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "10:04:17 [ INFO] HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:04:18 [ INFO] HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "10:04:38 [ INFO] Role:system You are a polite and helpful assistant.\n",
      "10:04:38 [ INFO] Role:human Who is the current Italian President?\n",
      "\n",
      "10:05:06 [ INFO] Role:system You are a polite and helpful assistant.\n",
      "10:05:06 [ INFO] Role:human Who is the current Italian President?\n",
      "\n",
      "10:05:06 [ INFO] Role:human Had he a brother?\n",
      "\n",
      "10:05:35 [ INFO] Role:system You are a polite and helpful assistant.\n",
      "10:05:35 [ INFO] Role:human Who is the current Italian President?\n",
      "\n",
      "10:05:35 [ INFO] Role:human Had he a brother?\n",
      "\n",
      "10:05:35 [ INFO] Role:human Who is the sister? Her name and further news about her?\n",
      "\n",
      "10:06:11 [ INFO] Role:system You are a polite and helpful assistant.\n",
      "10:06:11 [ INFO] Role:human Who is the current Italian President?\n",
      "\n",
      "10:06:11 [ INFO] Role:human Had he a brother?\n",
      "\n",
      "10:06:11 [ INFO] Role:human Who is the sister? Her name and further news about her?\n",
      "\n",
      "10:06:11 [ INFO] Role:human Ok, at least some public information about the brother? Is he alive?\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
