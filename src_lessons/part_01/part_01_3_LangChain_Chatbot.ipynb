{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faea30ca-3a60-4dfd-9c17-aa5822db3fc9",
   "metadata": {},
   "source": [
    "# Builds a LangChain chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8641e798-afa2-402c-a8a8-c6c81a9bb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain_core.messages.system import SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import logging as log\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a35e61ec-9390-4209-9b49-e3fbbe61cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.INFO, format='%(asctime)s [%(levelname)5s] %(message)s',datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acd5472c-f3e2-4df0-8233-8617673beb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(model:LlmModel.GeminiFlash, vendor:LlmVendor.Google, envVar:GOOGLE_API_KEY)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class LlmVendor( enum.Enum):\n",
    "    Google=1,\n",
    "    OpenAI=2\n",
    "\n",
    "class LlmModel( enum.Enum):\n",
    "    GeminiFlash=1,\n",
    "    GeminiPro=2\n",
    "    OpenAI=3\n",
    "    \n",
    "class LlmModelFactory():\n",
    "    def __init__(self, model: LlmModel, vendor: LlmVendor, envVar:str):\n",
    "        self._model = model\n",
    "        self._vendor= vendor\n",
    "        self._envVar= envVar\n",
    "\n",
    "        if not envVar in os.environ:\n",
    "            raise ValueError(f'{envVar} not found in the environment.')\n",
    "\n",
    "    @staticmethod\n",
    "    def createGoogleGeminiFlash(): \n",
    "        return LlmModelFactory(model= LlmModel.GeminiFlash,  \n",
    "                               vendor= LlmVendor.Google,\n",
    "                               envVar='GOOGLE_API_KEY')\n",
    "    @staticmethod\n",
    "    def modelName( llmModel: LlmModel):\n",
    "        match llmModel:\n",
    "            case LlmModel.GeminiFlash:\n",
    "                return \"gemini-1.5-flash\"\n",
    "            case LlmModel.GeminiPro:     \n",
    "                return \"gemini-1.5-pro\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'(model:{self._model}, vendor:{self._vendor}, envVar:{self._envVar})'\n",
    "\n",
    "    def createChatModel(self, \n",
    "                       maxOutputTokens=250,\n",
    "                       temperature=0.0):\n",
    "        match self._vendor:\n",
    "            case LlmVendor.Google:\n",
    "                return ChatGoogleGenerativeAI(model= LlmModelFactory.modelName(self._model), \n",
    "                                              max_output_tokens=maxOutputTokens, \n",
    "                                              temperature=temperature)\n",
    "                \n",
    "\n",
    "llmModelFactory= LlmModelFactory.createGoogleGeminiFlash()\n",
    "print(llmModelFactory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11bc2be1-8141-43b8-a6ad-69cdaf491582",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = llmModelFactory.createChatModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "783e2124-d608-4530-9467-ee3752c6ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [('system','You are a helpful assistant. That can translate from English to {language}'),\n",
    "           ('human','Translate the following text:\\n{text}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d216318-adc0-4d1f-873f-deb54a0abb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ChatPromptTemplate(messages) | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1f47bf4-335f-4c81-b2cf-a5a843bdd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result= chain.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f6c60e61-299f-496e-93a1-5073a7539be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ciao!'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce6b8f-757c-4594-af23-8009c7235300",
   "metadata": {},
   "source": [
    "## Other test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9b7ef4f-c975-4a96-8831-31e3dce394b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chainModelToParser = model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19cbc9f5-008d-4d65-a5b5-2c068b87e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [('system','You are a helpful assistant. That can translate from English to {language}'),\n",
    "           ('human','Translate the following text:\\n{text}')]\n",
    "promptTemplate= ChatPromptTemplate(messages)\n",
    "chain= promptTemplate | chainModelToParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6f98953-6c91-4636-b6f9-018fd0f9b500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How are you?  translates to:\\n\\n**Come stai?** (informal, used with friends and family)\\n\\nor\\n\\n**Come sta?** (formal, used with strangers or people you don't know well)\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result= chain.invoke({\"language\": \"Italian\", \"text\": \"How are you?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf40b4d9-05c4-4199-9709-f8f5c9f155c4",
   "metadata": {},
   "source": [
    "# Chatbot. It runs until the user types 'quit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb56702f-236a-485f-ac0e-2f6914d087e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role:   system\n",
      "Message:You are a polite and helpful assistant.\n",
      "\n",
      "Enter the next prompt:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Who is the current President of the USA?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of the USA is Joe Biden.\n",
      "Role:   system\n",
      "Message:You are a polite and helpful assistant.\n",
      "\n",
      "Role:   human\n",
      "Message:Who is the current President of the USA?\n",
      "\n",
      "Role:   ai\n",
      "Message:The current President of the USA is Joe Biden.\n",
      "\n",
      "Enter the next prompt:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " How is his wife called?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Biden's wife's name is Jill Biden.\n",
      "Role:   system\n",
      "Message:You are a polite and helpful assistant.\n",
      "\n",
      "Role:   human\n",
      "Message:Who is the current President of the USA?\n",
      "\n",
      "Role:   ai\n",
      "Message:The current President of the USA is Joe Biden.\n",
      "\n",
      "Role:   human\n",
      "Message:How is his wife called?\n",
      "\n",
      "Role:   ai\n",
      "Message:President Biden's wife's name is Jill Biden.\n",
      "\n",
      "Enter the next prompt:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " quit\n"
     ]
    }
   ],
   "source": [
    "messages= [('system','You are a polite and helpful assistant.')]\n",
    "chainModelToParser = model | StrOutputParser()\n",
    "\n",
    "while True:\n",
    "    for (role,message) in messages:\n",
    "        print(f'Role:   {role}')\n",
    "        print(f'Message:{message}\\n')\n",
    "    print('Enter the next prompt. quit to terminate:')\n",
    "    userPrompt= input()\n",
    "    if 'quit'==userPrompt.strip().lower():\n",
    "        break\n",
    "    messages.append( ('human',userPrompt))  \n",
    "    promptTemplate= ChatPromptTemplate(messages)\n",
    "    chain= promptTemplate | chainModelToParser\n",
    "    result= chain.invoke({})\n",
    "    print(result)\n",
    "    messages.append( ('ai',result))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f305c45-f1a1-45c7-ab13-c17d2168a3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
