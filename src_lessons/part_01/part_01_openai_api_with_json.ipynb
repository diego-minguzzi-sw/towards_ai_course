{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8241f207-72f2-40dd-9561-e852f8f6f329",
   "metadata": {},
   "source": [
    "# Part 1 Building our RAG AI Tutor - Using LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec78e98b-d403-49e6-af01-a760b5e19e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import logging as log\n",
    "import os\n",
    "import pprint\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec63be52-4054-43d9-8a5f-a3517eea96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "UrlCompletions = \"https://api.openai.com/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cefd97-981f-47ba-ba20-0dcba261d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.DEBUG, format='%(asctime)s [%(levelname)5s] - %(message)s',\n",
    "                  datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba4f15f-52f9-4fc6-82ed-dcc3d2064b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinishReason(enum.Enum):\n",
    "    Stop=0,\n",
    "    LengthExceeded=1\n",
    "\n",
    "def parseFinishReason( s: str):\n",
    "    if 'stop'==s:\n",
    "        return FinishReason.Stop        \n",
    "    elif 'length'==s:       \n",
    "        return FinishReason.LengthExceeded\n",
    "    raise ValueError(f'Invalid finish reason:{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0245713-9ce0-47a7-b817-0cfb6768f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlmResponse():\n",
    "  def __init__(self, content:str, \n",
    "               numPromptTokens: int, \n",
    "               numCompletionTokens: int, \n",
    "               finishReason: FinishReason):\n",
    "    self._content= content\n",
    "    self._numPromptTokens= numPromptTokens\n",
    "    self._numCompletionTokens= numCompletionTokens\n",
    "    self._finishReason= finishReason\n",
    "\n",
    "  @property\n",
    "  def content(self) -> str: return self._content\n",
    "\n",
    "  @property\n",
    "  def numPromptTokens(self) -> int: return self._numPromptTokens\n",
    "\n",
    "  @property\n",
    "  def numCompletionTokens(self) -> int: return self._numCompletionTokens\n",
    "\n",
    "  @property\n",
    "  def finishReason(self) -> FinishReason: return self._finishReason\n",
    "\n",
    "  def __str__(self):\n",
    "      return f'content:\\\"{ self._content}\\\"\\nnumPromptTokens:{ self._numPromptTokens}\\nnumCompletionTokens:{ self._numCompletionTokens}\\nfinishReason:{ self._finishReason.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b6788f-b6bc-49d7-ad57-2132d645c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def promptTranslationGetResponse( userPrompt: str, systemRole='You are a helpful assistant.', modelName='gpt-4o-mini', maxTokens=60, temperature=0.7):\n",
    "  log.debug('promptTranslationGetResponse started.')\n",
    "  OPEN_AI_KEY_NAME='OPENAI_API_KEY'\n",
    "  if not OPEN_AI_KEY_NAME in os.environ:\n",
    "    log.error(f'Environment variable {OPEN_AI_KEY_NAME} not set.')\n",
    "    return None\n",
    "  openaiKey=os.environ[OPEN_AI_KEY_NAME]\n",
    "\n",
    "  headers = {\n",
    "      \"Authorization\": f\"Bearer {openaiKey}\",\n",
    "      \"Content-Type\": \"application/json\",\n",
    "  }\n",
    "\n",
    "  # The data payload with your prompt and other parameters\n",
    "  data = {\n",
    "      \"model\": modelName,\n",
    "      \"messages\": [\n",
    "          {\n",
    "              \"role\": \"system\",\n",
    "              \"content\": systemRole\n",
    "          },\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": userPrompt\n",
    "          }\n",
    "      ],\n",
    "      \"max_tokens\": int(maxTokens),\n",
    "      \"temperature\": float(temperature),\n",
    "  }\n",
    "  log.debug(pprint.pformat(data))\n",
    "\n",
    "  response= requests.post(UrlCompletions, json=data, headers=headers)  \n",
    "  if 200!=response.status_code:\n",
    "    log.warn(f'promptTranslationGetResponse failed. status_code:{response.status_code}.')    \n",
    "  else:\n",
    "    log.debug('promptTranslationGetResponse terminated:success.')\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43becbb-4c8d-4381-aee3-612adab4bc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseOpenAIResponse( response) -> LlmResponse:\n",
    "  if 200!=response.status_code:\n",
    "    log.warn(f'Invalid response. status_code:{response.status_code}')    \n",
    "    return None  \n",
    "\n",
    "  responseStruct= response.json()  \n",
    "  choices= responseStruct['choices']\n",
    "  if len(choices)<=0:\n",
    "    log.error('The response has no content')\n",
    "    return None\n",
    "  choice= choices[0]    \n",
    "  content = choice['message']['content']\n",
    "\n",
    "  usage= responseStruct['usage']\n",
    "\n",
    "  finishReason= parseFinishReason(choice['finish_reason'])   \n",
    "  return LlmResponse( content, usage['prompt_tokens'], usage['completion_tokens'], finishReason)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c867c6-c9cb-483e-918c-2a202db6da6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:32 [DEBUG] - promptTranslationGetResponse started.\n",
      "15:54:32 [DEBUG] - {'max_tokens': 60,\n",
      " 'messages': [{'content': 'You are a helpful assistant that translates from '\n",
      "                          'English to French.',\n",
      "               'role': 'system'},\n",
      "              {'content': 'Bye, see you later.', 'role': 'user'}],\n",
      " 'model': 'gpt-4o-mini',\n",
      " 'temperature': 0.7}\n",
      "15:54:32 [DEBUG] - Starting new HTTPS connection (1): api.openai.com:443\n",
      "15:54:33 [DEBUG] - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "15:54:33 [DEBUG] - promptTranslationGetResponse terminated:success.\n"
     ]
    }
   ],
   "source": [
    "response= promptTranslationGetResponse(\"Bye, see you later.\",\n",
    "                                       systemRole='You are a helpful assistant that translates from English to French.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bea9eba-d747-42bc-ad34-aed823d82186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-ArQz3zEILosWwbUCIhG1Ej0J9NYUO',\n",
      " 'object': 'chat.completion',\n",
      " 'created': 1737298473,\n",
      " 'model': 'gpt-4o-mini-2024-07-18',\n",
      " 'choices': [{'index': 0,\n",
      "              'message': {'role': 'assistant',\n",
      "                          'content': 'Au revoir, à plus tard.',\n",
      "                          'refusal': None},\n",
      "              'logprobs': None,\n",
      "              'finish_reason': 'stop'}],\n",
      " 'usage': {'prompt_tokens': 29,\n",
      "           'completion_tokens': 8,\n",
      "           'total_tokens': 37,\n",
      "           'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0},\n",
      "           'completion_tokens_details': {'reasoning_tokens': 0,\n",
      "                                         'audio_tokens': 0,\n",
      "                                         'accepted_prediction_tokens': 0,\n",
      "                                         'rejected_prediction_tokens': 0}},\n",
      " 'service_tier': 'default',\n",
      " 'system_fingerprint': 'fp_72ed7ab54c'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pp(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d838f5-1840-4880-bd4f-71407b3f23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llmResponse = parseOpenAIResponse( response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7126e9fe-c9c9-4a80-9c79-73c1030b4323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:\"Au revoir, à plus tard.\"\n",
      "numPromptTokens:29\n",
      "numCompletionTokens:8\n",
      "finishReason:Stop\n"
     ]
    }
   ],
   "source": [
    "print(llmResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f0d6c-fb85-4960-8416-f488716b910a",
   "metadata": {},
   "source": [
    "## Hallucination examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e78d496-cb36-4944-9c4e-f93acd8a923b",
   "metadata": {},
   "source": [
    "### Lack of detailed knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5b4ecf2-2838-4ebb-960b-64dc83440df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:33 [DEBUG] - promptTranslationGetResponse started.\n",
      "15:54:33 [DEBUG] - {'max_tokens': 60,\n",
      " 'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "              {'content': 'What is the name of the Towards AI developed '\n",
      "                          'largest open-source model and what is its size?',\n",
      "               'role': 'user'}],\n",
      " 'model': 'gpt-4o-mini',\n",
      " 'temperature': 0.7}\n",
      "15:54:33 [DEBUG] - Starting new HTTPS connection (1): api.openai.com:443\n",
      "15:54:34 [DEBUG] - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "15:54:34 [DEBUG] - promptTranslationGetResponse terminated:success.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:\"The largest open-source model developed by Towards AI is called **GPT-NEOX**. As of my last knowledge update in October 2023, the largest version of GPT-NEOX is **20 billion parameters**.\"\n",
      "numPromptTokens:36\n",
      "numCompletionTokens:47\n",
      "finishReason:Stop\n",
      "The largest open-source model developed by Towards AI is called **GPT-NEOX**. As of my last knowledge update in October 2023, the largest version of GPT-NEOX is **20 billion parameters**.\n"
     ]
    }
   ],
   "source": [
    "response= promptTranslationGetResponse(\"What is the name of the Towards AI developed largest open-source model and what is its size?\")\n",
    "llmResponse = parseOpenAIResponse( response)\n",
    "print(llmResponse)\n",
    "print(llmResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690658a-04e0-47e9-9bdd-b50cb806172c",
   "metadata": {},
   "source": [
    "### Bias: profession gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a53b7264-a023-4ff6-b34c-a9677afc04ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:34 [DEBUG] - promptTranslationGetResponse started.\n",
      "15:54:34 [DEBUG] - {'max_tokens': 60,\n",
      " 'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "              {'content': 'Translate the following from English to Italian: A '\n",
      "                          'Nurse saved the situation yesterday.',\n",
      "               'role': 'user'}],\n",
      " 'model': 'gpt-4o-mini',\n",
      " 'temperature': 0.7}\n",
      "15:54:34 [DEBUG] - Starting new HTTPS connection (1): api.openai.com:443\n",
      "15:54:35 [DEBUG] - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "15:54:35 [DEBUG] - promptTranslationGetResponse terminated:success.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:\"Una infermiera ha salvato la situazione ieri.\"\n",
      "numPromptTokens:32\n",
      "numCompletionTokens:12\n",
      "finishReason:Stop\n",
      "Una infermiera ha salvato la situazione ieri.\n"
     ]
    }
   ],
   "source": [
    "response= promptTranslationGetResponse(\"Translate the following from English to Italian: A Nurse saved the situation yesterday.\")\n",
    "llmResponse = parseOpenAIResponse( response)\n",
    "print(llmResponse)\n",
    "print(llmResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "627b604e-4cb6-4774-a777-a37653d2819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:35 [DEBUG] - promptTranslationGetResponse started.\n",
      "15:54:35 [DEBUG] - {'max_tokens': 60,\n",
      " 'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "              {'content': 'Translate the following from English to Italian: An '\n",
      "                          'engineer saved the situation yesterday.',\n",
      "               'role': 'user'}],\n",
      " 'model': 'gpt-4o-mini',\n",
      " 'temperature': 0.7}\n",
      "15:54:35 [DEBUG] - Starting new HTTPS connection (1): api.openai.com:443\n",
      "15:54:36 [DEBUG] - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "15:54:36 [DEBUG] - promptTranslationGetResponse terminated:success.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:\"Un ingegnere ha salvato la situazione ieri.\"\n",
      "numPromptTokens:32\n",
      "numCompletionTokens:12\n",
      "finishReason:Stop\n",
      "Un ingegnere ha salvato la situazione ieri.\n"
     ]
    }
   ],
   "source": [
    "response= promptTranslationGetResponse(\"Translate the following from English to Italian: An engineer saved the situation yesterday.\")\n",
    "llmResponse = parseOpenAIResponse( response)\n",
    "print(llmResponse)\n",
    "print(llmResponse.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94d9ee-9b22-44c3-9d28-92d0266aca6c",
   "metadata": {},
   "source": [
    "### Access to the latest information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87632d2d-a8e0-4bda-9d6b-005d8ba10580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:36 [DEBUG] - promptTranslationGetResponse started.\n",
      "15:54:36 [DEBUG] - {'max_tokens': 60,\n",
      " 'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "              {'content': 'What is the date of your more recent available '\n",
      "                          'information?',\n",
      "               'role': 'user'}],\n",
      " 'model': 'gpt-4o-mini',\n",
      " 'temperature': 0.7}\n",
      "15:54:36 [DEBUG] - Starting new HTTPS connection (1): api.openai.com:443\n",
      "15:54:37 [DEBUG] - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "15:54:37 [DEBUG] - promptTranslationGetResponse terminated:success.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:\"My most recent available information is up to October 2023.\"\n",
      "numPromptTokens:28\n",
      "numCompletionTokens:14\n",
      "finishReason:Stop\n",
      "My most recent available information is up to October 2023.\n"
     ]
    }
   ],
   "source": [
    "response= promptTranslationGetResponse(\"What is the date of your more recent available information?\")\n",
    "llmResponse = parseOpenAIResponse( response)\n",
    "print(llmResponse)\n",
    "print(llmResponse.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd9b8083-4621-416e-8fff-d76810c00774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:54:37 [DEBUG] - promptTranslationGetResponse started.\n",
      "15:54:37 [DEBUG] - {'max_tokens': 100,\n",
      " 'messages': [{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      "              {'content': 'What is the latest Mission Impossible Movie? The '\n",
      "                          'latest Avengers?',\n",
      "               'role': 'user'}],\n",
      " 'model': 'gpt-4o-mini',\n",
      " 'temperature': 0.7}\n",
      "15:54:37 [DEBUG] - Starting new HTTPS connection (1): api.openai.com:443\n",
      "15:54:40 [DEBUG] - https://api.openai.com:443 \"POST /v1/chat/completions HTTP/1.1\" 200 None\n",
      "15:54:40 [DEBUG] - promptTranslationGetResponse terminated:success.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content:\"As of October 2023, the latest Mission Impossible movie is \"Mission: Impossible – Dead Reckoning Part One,\" which was released in July 2023. \n",
      "\n",
      "The latest Avengers movie is \"Avengers: Endgame,\" which was released in April 2019. However, there are upcoming Avengers films planned, including \"Avengers: The Kang Dynasty,\" scheduled for May 2026, and \"Avengers: Secret Wars,\" set for May 2027.\"\n",
      "numPromptTokens:29\n",
      "numCompletionTokens:96\n",
      "finishReason:Stop\n",
      "As of October 2023, the latest Mission Impossible movie is \"Mission: Impossible – Dead Reckoning Part One,\" which was released in July 2023. \n",
      "\n",
      "The latest Avengers movie is \"Avengers: Endgame,\" which was released in April 2019. However, there are upcoming Avengers films planned, including \"Avengers: The Kang Dynasty,\" scheduled for May 2026, and \"Avengers: Secret Wars,\" set for May 2027.\n"
     ]
    }
   ],
   "source": [
    "response= promptTranslationGetResponse(\"What is the latest Mission Impossible Movie? The latest Avengers?\", maxTokens=100)\n",
    "llmResponse = parseOpenAIResponse( response)\n",
    "print(llmResponse)\n",
    "print(llmResponse.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
