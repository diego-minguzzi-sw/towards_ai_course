{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939729d1-0e82-459c-a6b3-c061c04a89a6",
   "metadata": {},
   "source": [
    "# Part 1: Basic RAG with LlamaIndex\n",
    "<ul>\n",
    "  <li><a target=\"_blank\" href=\"https://docs.llamaindex.ai\">LlamaIndex Docs</a> </li>\n",
    "  <li><a target=\"_blank\" href=\"https://llamahub.ai/\">Llama Hub: third party integgrations with LlamaIndex</a> </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e425f4f0-5a9c-4c1f-8b95-b7c2b55a7880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document, VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import csv\n",
    "import logging as log\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bca65d2-0f88-4197-acfa-ff63ca08942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.basicConfig(level=log.INFO, format='%(asctime)s [%(levelname)5s] %(message)s',datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8059681e-eb7c-4ca6-bf31-ecde7020dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleApiEnvVar= 'GOOGLE_API_KEY'\n",
    "assert GoogleApiEnvVar in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a964b91-d396-44ad-8bf3-d85cfc7b060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TaiDatasetRootEnvVar='TAI_DATASET_ROOT'\n",
    "assert TaiDatasetRootEnvVar in os.environ\n",
    "TaiDatasetRoot = os.environ[TaiDatasetRootEnvVar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17af8413-8691-40eb-9b1f-9011757607c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFile= os.path.join(TaiDatasetRoot, 'rag_ai_tutor', 'mini-llama-articles.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc2dbb3-edc4-44a7-8715-3a3f3542f9c9",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "### Load the dataset using the csv package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e407de2b-ae3e-42f9-a265-6cc21d47a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(datasetFile, mode='r', encoding='utf-8') as csvFile:\n",
    "    csvReader = csv.reader(csvFile, delimiter=',')\n",
    "    next(csvReader) # Skip the first line\n",
    "    rows= [ row for row in csvReader]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39143355-52ed-48d4-9aae-c2eb07bb06b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:14\n",
      "0: Num fields:4\n",
      "1: Num fields:4\n",
      "2: Num fields:4\n",
      "3: Num fields:4\n",
      "4: Num fields:4\n",
      "5: Num fields:4\n",
      "6: Num fields:4\n",
      "7: Num fields:4\n",
      "8: Num fields:4\n",
      "9: Num fields:4\n",
      "10: Num fields:4\n",
      "11: Num fields:4\n",
      "12: Num fields:4\n",
      "13: Num fields:4\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows:{len(rows)}')\n",
    "for index,row in enumerate(rows):\n",
    "    print(f'{index}: Num fields:{len(row)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab580e1-9549-4361-b5fc-675869fc8214",
   "metadata": {},
   "source": [
    "### Creating Indexes (Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf795f04-927c-4833-ad50-a86145b1acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document( text=row[1], metadata={\"url\": row[2]}) for row in rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626cb364-9df4-46fb-abfe-99408977aefc",
   "metadata": {},
   "source": [
    "Adapted from <a target=\"\" href=\"https://docs.llamaindex.ai/en/stable/#getting-started\">LlamaIndex Getting started</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bdebeec-4c25-4e75-9a82-ad9c4c683b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa0537b87924c739f941cb898774436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8884f95f0d64ac898fec0fb84782ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:11:08 [ INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents,\n",
    "                                       embed_model=OpenAIEmbedding(model='text-embedding-3-small'),\n",
    "                                       transformations=[SentenceSplitter(chunk_size=768, chunk_overlap=64)],\n",
    "                                       show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "384e3f5a-4073-45c9-8db3-2e0d17a275ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "queryIndex = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39febe60-45c5-4686-9061-0246e0ad7efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:11:25 [ INFO] HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "23:11:27 [ INFO] HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 2 is available in four different model sizes: 7 billion, 13 billion, 34 billion, and 70 billion parameters.\n"
     ]
    }
   ],
   "source": [
    "response = queryIndex.query(\"How many parameters has Llama 2?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
